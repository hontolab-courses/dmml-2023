{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# 第2回：K-means & 階層的クラスタリング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "このHands-onでは下記の4種類のデータを用いて，K-meansと階層的クラスタリングを体験します．\n",
    "* アヤメの個体データ\n",
    "* 人工的な2次元データ\n",
    "* とある購買データ\n",
    "* 2018年度プロ野球打者成績データ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "Hands-onに先立って，必要なライブラリを読み込んでおきます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 表形式のデータを操作するためのライブラリ\n",
    "import pandas as pd\n",
    "\n",
    "# 行列計算をおこなうためのライブラリ\n",
    "import numpy as np\n",
    "\n",
    "# 機械学習用ライブラリsklearnのKmeansクラス\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 距離行列の計算のためのライブラリ\n",
    "import scipy.spatial.distance as distance\n",
    "\n",
    "# 階層的クラスタリング用のライブラリ\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, cut_tree\n",
    "\n",
    "# グラフ描画ライブラリ\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns;\n",
    "sns.set(style='ticks')\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# 警告文を表示させないおまじない\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "また，このHands-onでは日本語を含むグラフを生成するため，問題が生じないよう以下のおまじないコードを実行しておいてください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import japanize_matplotlib\n",
    "except:\n",
    "    !pip install japanize-matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import japanize_matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "\n",
    "## 例題1: アヤメデータに対するK-meansクラスタリング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "データマイニングや機械学習を学ぶ際，例題データとしてアヤメ（英語名:Iris）データがよく用いられます（[アヤメ](https://ja.wikipedia.org/wiki/%E3%82%A2%E3%83%A4%E3%83%A1)は植物の1つです）．決定木を体験する題材としても利用しました．\n",
    "このHands-onでもアヤメデータを使ってみましょう．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### データの準備\n",
    "以下のコードを実行して，アヤメのデータを読み込みましょう．\n",
    "下記コードを実行すると，変数`iris_df`（pandasデータフレーム）にアヤメのデータが読み込まれます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# Iris（アヤメ）の大きさに関するデータをロード\n",
    "iris = datasets.load_iris()\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_df['species'] = iris.target_names[iris.target]\n",
    "\n",
    "# 簡単のために，カラム名を修正しておく\n",
    "iris_df = iris_df.rename(\n",
    "    columns = {\n",
    "        'sepal length (cm)': 'sepal_length',\n",
    "        'sepal width (cm)': 'sepal_width',\n",
    "        'petal length (cm)': 'petal_length',\n",
    "        'petal width (cm)': 'petal_width'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "どんなデータが入っているか，iris_dfの中身をのぞいてみましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ロードしたデータの中身（最初の数件）を確認\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "このデータには，アヤメの「花弁（Petal）」と「がく（Sepal）」の大きさ，長さ，およびアヤメの品種に関する情報が入っています．1行1行がアヤメの個体に対応しています．\n",
    "格納されているアヤメの種類はsetosa, virginica, versicolorの3種類です．それぞれの品種について，50個ずつデータが入っています．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "\n",
    "### データの可視化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "このHands-onでは，品種（species）の情報は無視して，花弁とがくの大きさ・長さの4種類の指標に着目します．\n",
    "つまり**4次元**のデータを扱います．\n",
    "私たちは普段3次元の世界で生きているので，4次元のデータをイメージすることは難しいです．ですので，まずはデータを2次元にして，データの様子を可視化してみましょう．\n",
    "\n",
    "アヤメデータから花弁の大きさ，長さのみを取り出して，XY平面に点をプロットしてみましょう．Pandasデータフレームでは，``df.x``とすると表データ``df``の列``x``のデータを抜き出すことができます．点をプロットするには``plt.scatter``関数を用います．\n",
    "\n",
    "では，下記のコードを実行してみてください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(iris_df.sepal_length, iris_df.sepal_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "表示されたグラフ（散布図）を眺めてみてください．「データをグルーピングする」という観点で眺めたとき，何か特徴はつかめたでしょうか？心の目で眺めてみると，なんとなくですが，データ点が「左上」と「右下」で分かれているような気もします．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### K-meansの実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "今回のアヤメのデータには3種類の品種が混じっています．もし品種毎に性質がキレイに分かれるとすると，上記の点の集合も3グループに分かれてもよさそうです．ということで，今回はクラスタ数を**3**として，K-meansクラスタリングを実行してみましょう．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "アヤメデータを可視化したときは，花弁の長さと大きさの2指標に絞ってデータを眺めました．\n",
    "今回のK-meansクラスタリングでは，その2指標を特徴とする2次元データに対して分析をしてみましょう．\n",
    "\n",
    "完全なアヤメデータから「花弁の長さ」と「大きさ」のみに着目してデータを取り出すには以下のようにします．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_features = ['sepal_length', 'sepal_width']\n",
    "iris_df[target_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "このデータに対してK-meansを実行してみましょう．\n",
    "\n",
    "`sklearn`ライブラリで機械学習を行う場合，以下のようなステップを踏みます：\n",
    "1. 学習モデルのクラスインスタンスを作成\n",
    "2. データを入力し学習（fitメソッド）\n",
    "3. 学習済みモデルを用いて，分析結果を得る（transformやpredictメソッド）\n",
    "\n",
    "今回は`sklearn`ライブラリの``KMeans``クラスを用いてK-meansでクラスタリングを実行します．以下のコードを実行し，クラスタリングを実行します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# クラスタ数を3に指定\n",
    "model = KMeans(n_clusters=3, init='random')\n",
    "\n",
    "# クラスタリングを実行\n",
    "model.fit(iris_df[target_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "クラスタリングが完了しました．クラスタリング結果は`model`が保持しています．各データがどのクラスタに分類されたかを抽出するには，以下のコードを実行します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# クラスタリング結果をlabelsに格納\n",
    "labels = model.labels_\n",
    "\n",
    "# 表示\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "クラスタリングの結果をもとに，上で表示させた散布図にクラスタ毎に色をつけてみましょう．\n",
    "何も考えずに以下のコードを実行してみてください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    iris_df.sepal_length, iris_df.sepal_width,\n",
    "    c=labels,  # クラスタに応じて色分け\n",
    "    cmap=\"Accent\",\n",
    "    alpha=0.5 # 点の透明度\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "では，クラスタではなく**あらかじめ分かっている3種類の品種**ごとに，散布図に色づけをしてみましょう．下記のコードを実行します．クラスタリングの結果をもとに色分けした散布図と比較してみてください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 品種にIDを割り振る\n",
    "species_id = {'versicolor': 0, 'virginica': 1, 'setosa': 2}\n",
    "\n",
    "# 可視化\n",
    "plt.scatter(\n",
    "    iris_df.sepal_length, iris_df.sepal_width,\n",
    "    c=[species_id[s] for s in iris_df.species], # もともとの品種に応じて色分け\n",
    "    cmap=\"Accent\", # カラーパレット\n",
    "    alpha=0.5 # 点の透明度\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "散布図の右下で色が入り乱れています．このことから，花弁の大きさと長さだけではアヤメデータを3種類に分類することができないことが予想されます．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "少し脱線しますが，アヤメデータの各指標（特徴量）の相関関係を品種ごとに表示してみましょう．\n",
    "以下のコードを実行します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(\n",
    "    iris_df,\n",
    "    c=[species_id[s] for s in iris_df.species], # 品種ごとに色分け\n",
    "    figsize=(10, 10), s=80, alpha=0.8, cmap=\"Accent\" # 見た目の調整\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "図を眺めてみると，`petal_length`，`petal_width`の特徴も種ごとにある程度のまとまりがあるようにも見えます．そうならば，`sepal_length`，`sepal_width`の2種類だけでなく，他のすべての特徴をつかったほうがもっと高精度にグルーピングができそうです．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "では，先ほどのアヤメデータのK-meansクラスタリングを，2次元ではなく4次元データにして再度実行してみましょう．\n",
    "以下のコードを実行します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注目する特徴量\n",
    "target_features = ['sepal_length', 'sepal_width',\n",
    "                   'petal_length', 'petal_width' # 追加項目\n",
    "                  ]\n",
    "\n",
    "# クラスタリングを実行\n",
    "model = KMeans(n_clusters=3, init='random')\n",
    "model.fit(iris_df[target_features])\n",
    "\n",
    "labels = model.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "4次元データのクラスタリング結果を使って，散布図を色分けしてみましょう．\n",
    "以下のコードを実行します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    iris_df.sepal_length, iris_df.sepal_width,\n",
    "    c=labels,  # クラスタに応じて色分け\n",
    "    cmap=\"Accent\", alpha=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "どうでしょうか？3つの品種がより重なりなく分割されたような気がします．\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "```{attention} Q1. 類似度（1/2）（ユークリッド距離とコサイン類似度）\n",
    "\n",
    "下2次元のユークリッド空間上に，13個のデータ点が図のように分布している状況を考える（各点の座標については，下記コードのリスト``data``に収められている）．\n",
    "\n",
    "N次元空間上の任意の点$v_1$，$v_2$が与えられたとき，$v_1$と$v_2$のユークリッド距離を求める関数``calc_euclidean_dist(v1, v2)``，コサイン類似度を求める関数``calc_cosine_sim(v1, v2)``を実装せよ．\n",
    "さらに，下図の13つの点のすべての組み合わせについて，そのユークリッド距離とコサイン類似度を求めよ．,\n",
    "\n",
    "なお，実装する関数の第1引数および第2引数は，実数のリストを想定せよ．\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set()\n",
    "sns.set_style('ticks')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(2, 2), (3, 4), (5, 2), (10, 5), (9, 3),\n",
    "        (11, 4), (12, 3), (12, 6), (4, 10), (4, 8),\n",
    "        (6, 8), (7, 10), (7, 6)]\n",
    "\n",
    "xs, ys = zip(*data) # zipの逆操作\n",
    "\n",
    "# 可視化\n",
    "ax = sns.scatterplot(x=xs, y=ys)\n",
    "ax.set_xlim(0, 13)\n",
    "ax.set_ylim(0, 13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## 例題2: 人工データに対するK-meansクラスタリング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "K-meansクラスタリングの効果，特徴をもっと知るために，別のデータを分析してみましょう．\n",
    "\n",
    "次に用いるデータは人工的に作られた5000個の2次元データです．データに特に意味はありません．\n",
    "用いるデータは[University of Eastern Finlandの計算学部が公開しているデータセット](http://cs.joensuu.fi/sipu/datasets/)です．\n",
    "\n",
    "以下のコードを実行して，``s1_df``変数にデータを読み込んでください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://cs.joensuu.fi/sipu/datasets/s1.txt\"\n",
    "s1_df = pd.read_table(url, sep=\"\\s+\", header=None, names=['x', 'y'])\n",
    "\n",
    "# 最初の10件のデータを表示\n",
    "s1_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "データの傾向を見るために，XY平面にデータをプロットしてみましょう．\n",
    "下記のコードを実行します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(s1_df.x, s1_df.y, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "今回のデータの特徴は分かりやすいですね．目視レベルでは**15個**のクラスタに分かれているように見えます．\n",
    "\n",
    "では，K-meansクラスタリングによって，目論見どおりにデータを15個のクラスタに分けられるか試してみましょう．\n",
    "以下のコードを実行します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# クラスタリングを実行\n",
    "model = KMeans(n_clusters=15, init='random')\n",
    "model.fit(s1_df)\n",
    "\n",
    "# 結果を格納\n",
    "labels = model.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "アヤメのデータと同様に，クラスタリングの結果を踏まえて，散布図を色分けしてみましょう．\n",
    "今回はクラスタの数が15と多いので，下記のコードを実行して色分けのための準備を行います．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "下記コードを実行して，散布図を15のグループごとに色分けします．\n",
    "K-meansクラスタリングは，目論見どおりにデータを分割できていたでしょうか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    s1_df.x, s1_df.y,\n",
    "    c=labels,\n",
    "    alpha=0.4, # 透明度\n",
    "    s=40, # マーカーのサイズ\n",
    "    cmap=\"tab20_r\" # カラーパレット（20色対応）\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "```{attention} Q2. 類似度（2/2）（類似度の解釈）\n",
    "\n",
    "Q1で扱ったデータ集合において，点$v=(11, 4)$との最も類似する点（最近傍点）を求めたい．ユークリッド空間の各次元の意味，最近傍点の定義が下記のような設定である場合，\n",
    "点の類似性を評価する関数としてユークリッド距離，コサイン類似度のどちらを用いるのが適切か考察しながら，最近傍点を求めよ．\n",
    "\n",
    "1. 各点は都市の位置情報を表しており，第1次元は「緯度」，第2次元は「経度」を意味する．最近傍点として，**物理的距離が近い都市**を見つけたいケース．\n",
    "2. 各点はユーザの購買傾向を表しており，第1次元は「ジャンルAに属する商品を購入した回数」，第2次元は「ジャンルBに属する商品を購入した回数」を意味する．最近傍点として，**購買傾向が似ているユーザ**を見つけたいケース．\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "\n",
    "## 例題3: とある購買データに対する階層的クラスタリング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "あるeコマースサイトにおける購買データを用いて階層的クラスタリングを実行してみましょう．\n",
    "何も考えずに，以下のコードを実行してHands-onで用いるデータをダウンロードし，読み込みます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zipファイルをダウンロードし解凍\n",
    "!wget https://gihyo.jp/assets/files/book/2014/978-4-7741-6674-2/download/DM_sampledata.zip\n",
    "!unzip DM_sampledata.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データをpandasのデータフレームとして読み込む\n",
    "e_commerce_df = pd.read_table(\"DM_sampledata/ch5_3.txt\", header=0, sep=\" \")\n",
    "\n",
    "# ファイルを読み込んだので，元ファイル/ディレクトリを削除しておく\n",
    "!rm -rf DM_sampledata.zip DM_sampledata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "変数``e_commerce_df``に読み込まれたデータフレームには，\n",
    "* 書籍\n",
    "* 衣服\n",
    "* 化粧品\n",
    "* 食料品\n",
    "* 飲料\n",
    "\n",
    "を1年間で何回購入したかについて，100名の顧客のデータが記録されています（このデータは[書籍「手を動かしながら学ぶビジネスに活かすデータマイニング」のサポートページにて公開されているデータ](https://gihyo.jp/book/2014/978-4-7741-6674-2/support)です）．\n",
    "\n",
    "以下のコードを実行し，中身を確認してみましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最初の10件を表示\n",
    "e_commerce_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### データ間の距離の計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "Pythonで階層的クラスタリングを実行するには`scipy`ライブラリの``linkage``関数を用いるのが簡単です．\n",
    "``linkage``関数は入力（第1引数）として **ベクトル間の距離情報（を格納した行列データ）** を求めます．\n",
    "ここでベクトルとは，n個の特徴量からなるデータを意味します．今回の``e_commerce_df``のデータフレームでは，1行1行が1名の顧客情報を表すベクトルデータとなります．\n",
    "\n",
    "正攻法でやるならば，100行ある``e_commerce_df``の顧客データのすべての組み合わせを比較して，各顧客ベクトルの距離を計算する必要があります．`scipy`ライブラリはそれを簡単に実行してくれる便利な関数``distance.pdist``を提供しています．\n",
    "\n",
    "以下のコードを実行してベクトル間の距離を計算してみましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_matrix = distance.pdist(e_commerce_df, metric='euclidean')\n",
    "\n",
    "# 距離行列を表示\n",
    "pd.DataFrame(distance.squareform(dist_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "100行あるベクトルデータのすべての組み合わせについて距離を計算した結果（距離行列）が``dist_matrix``として得られました．\n",
    "この距離行列を使って階層的クラスタリングを実行してみましょう．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### 階層的クラスタリングの実行\n",
    "\n",
    "講義でも述べたように，階層的クラスタリングではクラスタの作り方の基準として\n",
    "* 最長距離法（complete linkage method）\n",
    "* 最短距離法（single linkage method）\n",
    "* 重心法（centroid method）\n",
    "* 群平均法（group average method）\n",
    "* ウォード法（Ward's method）\n",
    "\n",
    "などがあります．今回はウォード法を使ってみましょう．以下のコードを実行してみてください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_commerce_result = linkage(dist_matrix, method=\"ward\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "階層的クラスタリングの結果が変数``e_commerce_result``に格納されました．\n",
    "\n",
    "階層的クラスタリングにおいて，各要素（ベクトル）が徐々に併合されていく結果を示したものを**デンドログラム**と呼びます．デンドログラムを表示させてみましょう．以下のコードを実行してみてください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 図の大きさの設定\n",
    "plt.figure(figsize=(10, 14))\n",
    "\n",
    "# 図の表示\n",
    "fig = dendrogram(e_commerce_result,\n",
    "                 leaf_font_size=8, orientation='left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "デンドログラムが表示されると，階層的クラスタリングを実行したという気分になりますね！\n",
    "\n",
    "今回は顧客の一人一人について私たちは特に知識がないため，この図を眺めてもよく分かりません．そこで，適当な深さでデンドログラムの枝を切って，各要素をクラスタに分けてみましょう．つまりK-meansと同じようなことをします．その上で，\n",
    "各クラスタに入っている要素がどのような性質を持っているかを分析していましょう．\n",
    "\n",
    "デンドログラムの枝を切り，指定したクラスタ数に分割するには``cutree``関数を用います．``k``に数値を指定すると，デンドログラムをその数のクラスタに分割することができます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4つのクラスタに分割\n",
    "e_commerce_cluster = cut_tree(e_commerce_result, n_clusters=4)\n",
    "\n",
    "# 最初の10件のみ表示\n",
    "e_commerce_cluster[:10, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "変数``e_commerce_cluster``に100名の顧客のクラスタ割り当て番号が格納されました．\n",
    "\n",
    "さて，クラスタリングの結果は変数``e_commerce_cluster``に得られましたが，各クラスタがどのような購買傾向を持っているかを分析するには，``e_commerce_df``データと照らし合わせる必要があります．\n",
    "そこで，以下のコードを実行して，``e_commerce_cluster``と``e_commerce_df``を結合してみましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結合\n",
    "new_e_commerce_df = e_commerce_df.assign(\n",
    "    cluster_id = e_commerce_cluster[:, 0]\n",
    ")\n",
    "\n",
    "# 先頭の数件のみ表示\n",
    "new_e_commerce_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "各顧客データがどのクラスタに分類するかのデータが得られました．このデータを用いて，クラスタ毎に書籍の平均購買数，衣類の平均購買数などを調べてみましょう．\n",
    "\n",
    "今回の分析のように，クラスタ毎に何らかの情報をまとめて計算することを**集約演算**と呼びます．\n",
    "やや複雑に見えますが，以下のコードを実行してみてください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_e_commerce_df.groupby(\n",
    "    'cluster_id' # cluster_idでデータをまとめる\n",
    ").agg(\n",
    "    'mean' # まとまり毎に平均値を算出\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "クラスタ毎に書籍，衣類，化粧品，食料品，飲料の平均購買数が求まりました．クラスタ毎に少しずつ特徴が異なることが確認できます．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "```{attention} Q3. 階層的クラスタリング\n",
    "\n",
    "Q1で扱った13個のデータ点について，階層的クラスタリング法を用いて段階的にクラスタに分割したい．\n",
    "\n",
    "\n",
    "``scipy.cluster.hierarchy``ライブラリの``linkage``関数および``dendrogram``関数を用いて，Q1で扱ったデータに階層的クラスタリングを適用せよ．その際，階層的クラスタリングのクラスタ生成手法として下記3つの方法を用いて，クラスタの生成過程を結果を比較せよ：\n",
    "\n",
    "* セントロイド法（centroid）\n",
    "* 最短距離法（single linkage）\n",
    "* 最長距離法（complete linkage）\n",
    "\n",
    "なお，クラスタ間の距離の尺度にはユークリッド距離を用いること．\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## 例題4: 2018年度プロ野球打者成績データに対する階層的クラスタリング\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "例題3のデータは見ず知らずの顧客のデータであったため，クラスタリングをしても予想される結果がイメージしにくかったと思います．そこで次は実データを分析してみましょう．\n",
    "下記コマンドを実行して，Hands-onで用いるデータを読み込みます． このデータは2018年度のプロ野球において，規定打席に達した打者の成績（例：「打率」「出塁率」「長打率」）を記録したものです．\n",
    "\n",
    "※ 本データは，過去に講師が[日本プロ野球機構の公式サイト](https://npb.jp/)から手作業で取得したものです．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "url = \"https://raw.githubusercontent.com/hontolab-courses/dmml-2023/main/dataset/baseball_stats_2018.tsv\"\n",
    "stats_df = pd.read_table(url, header=0, sep=\"\\t\", index_col='選手名')\n",
    "\n",
    "# 最初の数件を表示\n",
    "stats_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "このデータに対して，階層的クラスタリングを実行して傾向が似通った選手をグルーピングしてみましょう．\n",
    "\n",
    "データをご覧になると分かるように，``stats_df``には「打率」「安打数」「ホームラン数」といった成績情報以外に「チーム名」（とデータのラベルとして「選手名」）が含まれています．\n",
    "今回の分析では野手成績に関係する「打率」〜「長打率」だけに焦点をしぼって分析をします．\n",
    "\n",
    "``stats_df``では「打率」〜「長打率」は1〜17列目（0列スタート）に格納されています．\n",
    "``stats_df``から1〜17列目だけを抜き出すには，下記のようなコードを書きます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df.iloc[:, 1:17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "この方法を使って，選手データをクラスタリングしてみましょう．\n",
    "\n",
    "例題3と同様，今回の分析では階層的クラスタリングのタイプとして**ウォード法**を用いることにします．\n",
    "下記のコードを実行すると，階層的クラスタリングを行い，その結果をデンドログラムとして表示します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 距離行列の計算\n",
    "stats_dist_matrix = distance.pdist(stats_df.iloc[:, 1:17], metric='euclidean')\n",
    "\n",
    "# 階層的クラスタリングの実行\n",
    "stats_result = linkage(stats_dist_matrix, method=\"ward\")\n",
    "\n",
    "# デンドログラムの表示\n",
    "japanize_matplotlib.japanize() \n",
    "plt.figure(figsize=(10, 10))\n",
    "fig = dendrogram(stats_result, labels=stats_df.index, \n",
    "                leaf_font_size=9, orientation='left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "デンドログラムが表示されました．プロ野球に関心のある方からご覧になって，このクラスタリング結果は妥当なものでしょうか？\n",
    "\n",
    "例題3と同様に，各クラスタの平均的なスコアを計算してみましょう．\n",
    "図を見ると，今回の結果から，データはざっくり見ると6クラスタに分かれそうです．\n",
    "とりあえず6クラスタに分けたときに，各クラスタの平均スコアがどうなっているかを分析してみましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6つのクラスタに分割\n",
    "stats_cluster = cut_tree(stats_result, n_clusters=6)\n",
    "\n",
    "# クラスタ情報と選手データを結合\n",
    "new_stats_df = stats_df.assign(\n",
    "    cluster_id = stats_cluster[:, 0]\n",
    ")\n",
    "\n",
    "# 各クラスタの平均スコアを計算\n",
    "new_stats_df.groupby(\n",
    "    'cluster_id' # cluster_idでデータをまとめる\n",
    ").agg(\n",
    "    'mean' # まとまり毎に平均値を算出\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "各クラスタの特徴は以下のような感じでしょうか：\n",
    "* 第1クラスタ: 打率も高く，ホームランも盗塁もできるユーティリティプレーヤー\n",
    "* 第2クラスタ: ホームランヒッター\n",
    "* 第3クラスタ: 打率もホームランもそこそこ高い6番バッタータイプ\n",
    "* 第4クラスタ: これといって特徴はない\n",
    "* 第5クラスタ: 出塁率が高く盗塁も多く足が速い，リードオフ・マンタイプ\n",
    "* 第6クラスタ: 打率は高くないが，堅実に犠打でランナーを進める，2番バッタータイプ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
