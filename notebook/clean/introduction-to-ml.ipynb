{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# 第2回：決定木から始める機械学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "このHands-onでは，機械学習手法のひとつである**決定木**を使って，あらかじめ与えられたデータから，未知データを分類する規則を抽出・適用する**教師あり学習**を体験します．この演習で用いるデータは以下の通りです：\n",
    "\n",
    "* アヤメ（花の種類）のデータ\n",
    "* タイタニック号の乗船者データ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "演習に先立って，必要なライブラリを準備します．まず，Google Colaboratoryに\n",
    "* graphviz\n",
    "* category_encoders\n",
    "\n",
    "の2つのライブラリをインストールするために， 以下のコードをGoogle Colaboratoryで実行します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import category_encoders\n",
    "    import graphviz\n",
    "except:\n",
    "    !pip install graphviz\n",
    "    !pip install category_encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "続けて，必要なライブラリを読み込みます．以下のコードを実行してください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 表形式のデータを操作するためのライブラリ\n",
    "import pandas as pd\n",
    "\n",
    "# 行列計算をおこなうためのライブラリ\n",
    "import numpy as np\n",
    "\n",
    "# 機械学習用ライブラリsklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# その他\n",
    "import category_encoders\n",
    "\n",
    "# グラフ描画ライブラリ\n",
    "from graphviz import Source\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "\n",
    "---\n",
    "## 例題1: アヤメ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "データマイニングや機械学習を学ぶ際，例題データとしてアヤメ（英語名:Iris）データがよく用いられます（[アヤメ](https://ja.wikipedia.org/wiki/%E3%82%A2%E3%83%A4%E3%83%A1)は植物の1つです）． 決定木アルゴリズムを体験する題材として，このHands-onでもアヤメデータを使ってみましょう．\n",
    "\n",
    "以下のコードを実行して，アヤメのデータを読み込みます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# Iris（アヤメ）の大きさに関するデータをロード\n",
    "iris = datasets.load_iris()\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_df['species'] = iris.target_names[iris.target]\n",
    "\n",
    "# 簡単のために，カラム名を修正しておく\n",
    "iris_df = iris_df.rename(\n",
    "    columns = {\n",
    "        'sepal length (cm)': 'sepal_length',\n",
    "        'sepal width (cm)': 'sepal_width',\n",
    "        'petal length (cm)': 'petal_length',\n",
    "        'petal width (cm)': 'petal_width'\n",
    "    }\n",
    ")\n",
    "\n",
    "# 最初の数件を表示\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "このアヤメデータには，花弁（petal）の長さ・幅，がく（sepal）の長さ・幅，品種が記されています．例題1の目標は，**花弁の長さ・幅，がくの長さ・幅から品種を推定する予測モデルを構築**することです．早速，決定木を用いて予測モデルを構築してみましょう．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "一般に教師あり学習で予測を行うモデルを構築する際には，データを**学習用（訓練）データ**と**評価用データ**に分割してデータ分析を行います．以下のコードを実行して，先ほど用意したデータを学習用（70%）と評価用（30%）に分割します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データを学習用（70%）と評価用（30%）に分割する\n",
    "iris_train_df, iris_test_df = train_test_split(\n",
    "                                iris_df, test_size=0.3,\n",
    "                                random_state=1,\n",
    "                                stratify=iris_df.species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "変数``iris_test_df``には品種情報も含まれますが，予測モデルの性能評価の際には，品種情報が未知であるとして予測を行い，予測結果と（隠しておいた）品種情報を照らし合わせて評価することになります．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "では，教師あり学習のひとつである決定木アルゴリズムを適用してみましょう．``iris_train_df``に決定木アルゴリズムを適用して，品種を見分けるルールを抽出（学習）しましょう．決定木アルゴリズムは`sklearn`ライブラリの``DecisionTreeClassifier``クラスを使って実行できます．下記コードを実行してみてください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_trainは，品種（Species）以外のすべての指標\n",
    "features = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "X_train = iris_train_df[features]\n",
    "\n",
    "# y_trainは品種の指標\n",
    "y_train = iris_train_df.species\n",
    "\n",
    "# 学習\n",
    "model = DecisionTreeClassifier(criterion='entropy',\n",
    "                               random_state=12345) # 初期値を固定\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "品種を予測するルールが学習されました．予測ルールをわかりやすく可視化してみましょう．以下のコードを実行してみてください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Source(export_graphviz(model, out_file=None,\n",
    "                       feature_names=features,\n",
    "                       class_names=['setosa', 'versicolor', 'virginica'],\n",
    "                       proportion=True,\n",
    "                       filled=True, rounded=True # 見た目の調整\n",
    "                      ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "分類ルールが木のように枝分かれした形で可視化されました．この可視化結果が，今回の教師あり学習アルゴリズムが **決定「木」** と呼ばれる所以です．\n",
    "\n",
    "結果の見方ですが，各四角が分類ルールの分岐をあわらしています．四角の下に書かれた文字情報が分岐条件を示しています．四角中に書かれた文字は，四角に至るまでに適用された分岐条件を満たすと，\n",
    "* その条件を満たすデータが全体の何パーセントあるか\n",
    "* ラベルごとの分類結果の割合が何パーセントか\n",
    "\n",
    "を示しています．例えば，上図の上から3段目の左にある「class=versicolor, value=\\[0.0, 1.00, 0.0\\]」という四角は，\n",
    "* 花弁（petal）の長さが2.6より大きい，かつ花弁（petal）の長さが4.75以下の場合，その個体は100%の確率でversicolorであること\n",
    "* この条件にマッチする個体はデータセットに28.6%存在すること\n",
    "\n",
    "を示しています．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "さて，ここまでやったことは予測のためのルール（モデル）の構築でした．構築した予測モデルを使って，未知のデータを予測してみましょう．この例題の冒頭で，変数``iris_test_df``に**予測モデルの構築に使われていないデータ**を別途用意していたことを思い出しましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最初の数件を表示\n",
    "iris_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "先ほど構築した予測モデルをこの``iris_test_df``に適用して，未知データのアヤメの品種を予測してみましょう．構築した予測モデル``iris_model``を用いて未知データを予測するには``predict``関数を用います．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評価用データの特徴量と正解ラベルを取得\n",
    "X_test = iris_test_df[features]\n",
    "y_test = iris_test_df.species\n",
    "\n",
    "# 予測モデルを使って，品種が未知の個体の品種を推定\n",
    "iris_predicted = model.predict(X_test)\n",
    "\n",
    "# 予測結果の一部を表示\n",
    "iris_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "予測結果が変数``iris_predicted``に格納されました．``iris_test_df``の列``Species``には実際の品種情報が格納されていました．これと予測結果と照らし合わせて，予測性能を評価してみましょう．\n",
    "\n",
    "予測性能の評価指標には様々なものがありますが，ここでは精度（accuracy）を計算しましょう．精度は「予測結果のうち， **各個体の品種について，予測モデルが予測したものと，実際の品種が一致したケースの割合」** を意味します．精度の計算には`sklearn`の`accuracy_score`関数を用います．第1引数に予測結果，第2引数に実際の結果を入力します．以下のコードを実行してみましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(iris_predicted, iris_test_df.species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "上記結果によると，Accuracyは約97.8%を示しており，かなりの精度で品種を予測できていることが分かります．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "\n",
    "---\n",
    "## 例題2: タイタニック号の乗船者データ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "1912年4月14日，処女航海中の豪華客船タイタニック号は多くの乗船者を乗せたまま沈没しました．タイタニックとその事故は，映画化されるなどして世界的に有名です．\n",
    "乗船者に関する情報が残っていたために，事故後，多くの人が事故に関する分析を行いました．私たちもタイタニック号の乗船者情報を用いて，生死を分けた条件について分析を行ってみましょう．\n",
    "\n",
    "以下のコードを実行して，タイタニック号の乗船者（の一部）のデータを読み込みましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "url = \"https://raw.githubusercontent.com/hontolab-courses/dmml-2022/main/dataset/titanic_train.csv\"\n",
    "titanic_df = pd.read_table(url, header=0, sep=\",\")\n",
    "\n",
    "# 生存情報を分かりやすくする\n",
    "titanic_df = titanic_df.assign(\n",
    "    Survived = lambda df: df.Survived.map({1: 'survived', 0: 'died'})\n",
    ")\n",
    "\n",
    "# 最初の数件のみ表示\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "様々な情報が表示されました．変数``titanic_train_df``に格納されたデータの属性（列名）の詳細は以下の通りです：\n",
    "\n",
    "* PassengerId: 乗船者を識別するためのID\n",
    "* Survived: ある乗船者が沈没事故で生き残った否かを示すフラグ．\n",
    "* Pclass: チケットの等級．1は1等乗客，2は2等乗客，3は3等乗客を表す\n",
    "* Name: 乗客名\n",
    "* Sex: 性別\n",
    "* Age: 年齢\n",
    "* SibSp: タイタニック号に同乗した兄弟もしくは配偶者の数\n",
    "* Parch: タイタニック号に乗船した両親もしくは子どもの数\n",
    "* Ticket: チケット番号\n",
    "* Fare: 乗船料金\n",
    "* Cabin: 客室番号\n",
    "* Embarked: 乗船した港．C = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "このデータを用いて，どんな乗客が生き残れたのかを予測できるようにしましょう．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "決定木を適用する前に，``titanic_df``データに対して簡易的な分析を行い，各データ属性と生存情報との関係を眺めてみましょう．\n",
    "以下のコードを実行すると， **乗客の等級（Pclass）と生存の有無（Survived）** の属性の値を集計して，ある等級の乗客のうち生き残った方の割合が表示されます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(titanic_df['Survived'], titanic_df['Pclass'], normalize='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "分析の結果，どうやら等級が高い（数値が小さい）ほど生き残っている方の割合が大きいようです．等級以外の属性でも同様の分析を行ってみてください．例えば，性別（Sex）と生存の有無の関係は以下のコードで得られます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(titanic_df['Survived'], titanic_df['Sex'], normalize='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "決定木アルゴリズムを適用する前に，データの欠損を確認しておきます．\n",
    "収集したデータの一部が欠損していることはよくあることです．欠損値がデータに含まれると，機械学習のアルゴリズムがうまく動作しない場合があります．\n",
    "\n",
    "欠損値がある場合の対応は，\n",
    "* 欠損しているデータを捨てる\n",
    "* 欠損値を代表的な値で埋める\n",
    "\n",
    "といったアプローチが採られることが多いです．欠損しているデータを捨ててしまうと，学習に用いる貴重なデータが減りますので，今回は欠損値を代表値で埋めます．\n",
    "\n",
    "まず，以下のコードを走らせて，欠損値を確認してみましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "上の結果から，Age，Cabin，Embarkedに欠損値が含まれるようです．Cabinは乗船客に与えられた固有の情報で，生存者の予測には役立ちません．それゆえ，AgeとEmbarkedのみ欠損値を埋めることにします．\n",
    "\n",
    "欠損値を埋めるには様々な方法が提案されていますが，今回は\n",
    "* Ageは中央値\n",
    "* Embarkedは最頻値\n",
    "\n",
    "で埋めることにします．以下のコードを実行してください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embarkedの欠損を最頻値で埋める\n",
    "titanic_df[\"Embarked\"] = titanic_df[\"Embarked\"].fillna(titanic_df[\"Embarked\"].mode().iloc[0]) \n",
    "\n",
    "# Ageを中央値で埋める\n",
    "titanic_df[\"Age\"] = titanic_df[\"Age\"].fillna(titanic_df[\"Age\"].median()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "これで欠損値はなくなりました．\n",
    "それでは決定木アルゴリズムを適用してみましょう．例題1と同様，まず，用意したデータを学習用（70%）と評価用（30%）に分割します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データを学習用（70%）と評価用（30%）に分割する\n",
    "titanic_train_df, titanic_test_df = train_test_split(\n",
    "                                        titanic_df, test_size=0.3,\n",
    "                                        random_state=1,\n",
    "                                        stratify=titanic_df.Survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "変数``titanic_test_df``には生存の有無の情報も含まれますが，予測モデルの性能評価の際には，生存情報が未知であるとして予測を行い，予測結果と（隠しておいた）生存情報を照らし合わせて評価することになります．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "簡易的な分析を行ってみると，生存の有無を識別するために有効な指標がありそうな気もします．しかし実際には，複数の指標が絡み合って生存の有無が決まっていると思われます．このような状況で，指標（特徴量）同士の複雑な関係性を考慮しながら，予測のためのルールを抽出するのが**教師あり学習**です．\n",
    "\n",
    "早速，決定木アルゴリズムを適用してみましょう．まずは決定木を適用するデータを整形します．データを眺めると，氏名（Name）やチケット番号（Ticket），客室番号（Cabin）は各乗船者に固有に与えられた情報であることが分かります．これら特徴量は生存者の予測には役に立たないため，それ以外の情報を利用することにします．\n",
    "\n",
    "下記コードを実行して，決定木を適用する際に注目する指標を，変数``target_features``に格納しておきます．さらに，\n",
    "``titanic_train_df``から上記指標に関するデータのみを抽出します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注目する指標\n",
    "target_features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "\n",
    "# 以下のように書けば，target_featuresの指標のみに注目してデータを抽出できる\n",
    "titanic_train_df[target_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "性別（Sex）や乗船した港（Embarked）は数値情報ではなくカテゴリ情報です．多くの機械学習は数値を受け取って処理をするので，カテゴリ情報も数値情報に変換しておいた方が都合がよいです．ここでは，「EmbarkedがSであることをEmbarked_Sが1，EmbarkedがSでないことをEmbarked_S=0」となるような変換をおこなうことにします．\n",
    "\n",
    "下記コードがその準備となります．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = category_encoders.OneHotEncoder(cols=['Embarked', 'Sex'], use_cat_names=True)\n",
    "encoder.fit(titanic_train_df[target_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "それでは，``titanic_train_df``に決定木アルゴリズムを適用して，生存の有無のルールを抽出（学習）しましょう．決定木アルゴリズムは``DecisionTreeClassifier``クラスを用いて実行できます．下記コードを実行してみてください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測に用いる生存情報以外のすべての指標をX_trainに\n",
    "X_train = titanic_train_df[target_features]\n",
    "\n",
    "# カテゴリ変数を数値情報に変換\n",
    "X_train = encoder.transform(X_train)\n",
    "\n",
    "# y_trainは生存有無をあらわす指標\n",
    "y_train = titanic_train_df.Survived\n",
    "\n",
    "# 学習\n",
    "model = DecisionTreeClassifier(criterion='entropy',\n",
    "                               random_state=12345, # 初期値を固定\n",
    "                               max_depth=3) # 木の深さを3に限定\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "生存の有無を予測するルールが学習されました．生存の有無を予測するためのルールをわかりやすく可視化してみましょう．以下のコードを実行してみてください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Source(export_graphviz(model, out_file=None,\n",
    "                       feature_names=X_train.columns,\n",
    "                       class_names=['died', 'survived'],\n",
    "                       proportion=True,\n",
    "                       filled=True, rounded=True # 見た目の調整\n",
    "                      ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "分類ルールが得られました．\n",
    "\n",
    "結果を解釈してみましょう．例えば，上図の上から3段目，左端にある「class=survived, entropy=0.258」という四角は，\n",
    "* 性別が女性であり（Sex_male<=0.5: True），乗船クラスが1等もしくは2等クラス（Pclass<=2.5: True）の乗客は95.7%の確率で生存したこと\n",
    "* その条件にマッチする乗客は，全体の18.5%存在すること\n",
    "\n",
    "を示しています．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "なんとなく予測ルールは分かりましたが，各指標が予測にどの程度影響があるかを調べてみましょう．以下のコードを実行します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, importance in zip(X_train.columns, model.feature_importances_):\n",
    "    print(\"{}\\t{}\".format(feature, importance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "この結果からも，**性別**や**等級**が生存に大きく影響を与えていたことがうかがえます．\n",
    "\n",
    "さて，ここまでやったことは予測のためのルール（モデル）の構築でした．構築した予測モデルを使って，未知のデータを予測してみましょう．この例題の冒頭で，変数``titanic_test_df``に**予測モデルの構築に使われていないデータ**を別途用意していたことを思い出しましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最初の数件を表示\n",
    "titanic_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "先ほど構築した予測モデルをこの``titanic_test_df``に適用して，生存の有無を予測してみましょう．構築した予測モデル``model``を用いて未知データを予測するには``predict``メソッドを用います．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_testは，生存情報以外のすべての指標\n",
    "X_test = titanic_test_df[target_features]\n",
    "\n",
    "# カテゴリ変数を計算しやすく変換する\n",
    "X_test = encoder.transform(X_test)\n",
    "\n",
    "# 予測\n",
    "y_predicted = model.predict(X_test)\n",
    "\n",
    "# 予測結果（最初の10件）\n",
    "y_predicted[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "予測結果が変数``y_predicted``に格納されました．``titanic_test_df``の列``Survived``には実際の生存情報が格納されていました．これと予測結果と照らし合わせて，予測性能を評価してみましょう．以下のコードを実行して，予測性能の評価を行います．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_testは生存の指標\n",
    "y_test = titanic_test_df.Survived\n",
    "\n",
    "accuracy_score(y_predicted, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "色々情報が出てきましたが，``Accuracy``という数値を見てください．Accuracyは予測結果のうち，\n",
    "**実際に生存した乗客を予測モデルが「生存」と予測し，死亡した乗客を予測モデルが「死亡」と予測できたケースの割合**を示しています．\n",
    "\n",
    "上記結果によると，Accuracyは約76.1%を示しており，そこそこの割合で生存の有無を予測できていることが分かります．\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## 演習課題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "以下のコードを実行して`income_df`に格納されるデータは，ある年にアメリカで実施された国勢調査のデータである．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "income_df = pd.read_table(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\", sep=',', header=None)\n",
    "\n",
    "# 列名（特徴）に名前を付ける\n",
    "income_df.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', \n",
    "                     'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "\n",
    "# データ表示（先頭5件）\n",
    "income_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "データ中の列名（特徴量）の意味は以下の通りである：\n",
    "\n",
    "* age: 年齢（整数）\n",
    "* workclass: 雇用形態（公務員，会社員など）\n",
    "* fnlwgt: 使わない\n",
    "* education: 学歴\n",
    "* education-num: 使わない\n",
    "* marital-status: 婚姻状態\n",
    "* occupation: 職業\n",
    "* relationship: 家族内における役割\n",
    "* race: 人種\n",
    "* sex: 性別\n",
    "* capital-gain: 使わない\n",
    "* capital-loss: 使わない\n",
    "* hours-per-week: 週あたりの労働時間（整数値）\n",
    "* native-country: 出身国\n",
    "* income: 年収（50Kドル以上，50Kドル未満の二値）\n",
    "\n",
    "このデータに対して決定木アルゴリズムを適用して，ある人物が年間収入が50Kドル以上か未満かを分類する機械学習モデルを構築したい．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### 課題1\n",
    "機械学習モデルを構築する前に，基礎データとして`income_df`データに含まれる調査対象者の年齢，性別，年収の分布を知りたい．\n",
    "年齢に関するヒストグラム（階級数は10）を作成せよ．また，性別（男，女），年収（50K以上，50K未満）について，属性値に対応する人数を求めよ．\n",
    "\n",
    "* ヒント1: ヒストグラムの作成には`pandas.series.hist`関数を用いるとよい（[参考](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.hist.html)）\n",
    "* ヒント2: 要素の出現頻度を求めるには`pandas.series.value_counts`メソッドを用いるとよい（[参考](https://note.nkmk.me/python-pandas-value-counts/)）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### 課題2\n",
    "``income_df``データを集約し，学歴ごとに年間収入クラスの内訳（割合）を調べよ．\n",
    "\n",
    "* ヒント3: pandasのcrosstabメソッドを使う（タイタニックの例を再訪すること）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### 課題3\n",
    "`income_df`データに決定木アルゴリズムを適用し，年収（`income`）の分類における各属性（列）の寄与度を求めよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### 課題4\n",
    "課題3の結果をもとに年収分類に寄与する特徴量を（最大5つ）特定し，その特徴量のみを用いて再度決定木モデルを構築せよ．その際，できる限りシンプルなモデルになるよう，あまり木が深くならないよう調整すること．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### 課題5\n",
    "課題4で構築した決定木を可視化し，年収の多寡に影響を与える条件について考察せよ．"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
