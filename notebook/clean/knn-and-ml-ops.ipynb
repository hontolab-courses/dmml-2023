{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "465cea19-d4ba-4309-981c-d138cccaad78",
   "metadata": {},
   "source": [
    "# 第4回: K近傍法 & 教師あり学習のお作法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacc4604-c52e-4131-8278-245930671c82",
   "metadata": {},
   "source": [
    "このHands-onでは下記3種類のデータを用いて，K近傍法と教師あり学習のお作法について体験します．\n",
    "* 手書き数字画像\n",
    "* 人工的に作られたある2次元データ\n",
    "* ある時期のアメリカ合衆国の年収調査データ\n",
    "\n",
    "Hands-onに先立って，必要なライブラリを読み込んでおきます．\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ae4547-2006-4d4c-b713-731d1ab08d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 表形式のデータを操作するためのライブラリ\n",
    "import pandas as pd\n",
    "\n",
    "# 行列計算をおこなうためのライブラリ\n",
    "import numpy as np\n",
    "\n",
    "# データセット\n",
    "from sklearn import datasets\n",
    "\n",
    "# K近傍法を実行するためのクラス\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# ロジスティック回帰を実行するためのクラス\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 決定木を実行するためのクラス\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 交差検証を行うためのクラス\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# 精度，マクロ精度，適合率，AUCを評価するための関数\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import precision_score, roc_auc_score\n",
    "\n",
    "# データ変換のためのクラス\n",
    "import sklearn.preprocessing as preprocessing\n",
    "\n",
    "# データ分割のための関数\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# グラフ描画ライブラリ\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8491d1fa-d53d-4f4a-97cd-d9ad26279b06",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "\n",
    "---\n",
    "## 例題1: MNIST手書き数字データ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a7b513-3b62-4af4-b03c-48184052f33a",
   "metadata": {},
   "source": [
    "例題1では，K近傍法を用いて手書き数字の識別の体験をします．\n",
    "用いるデータは，かの有名な[MNISTデータセット](http://yann.lecun.com/exdb/mnist/)です．\n",
    "今回は，`scikit-learn`ライブラリに梱包された8x8ピクセルの領域に描かれた手書き数字のグレースケール画像のデータセットを用います．\n",
    "データセット中の手書き数字は**0から9の数**に対応しています．\n",
    "また，手書き画像データは**各ピクセルに0から255の数値**が割り当てられており，その数字によって白黒の濃淡がつけられています．\n",
    "\n",
    "以下のコードを実行してMNISTデータセットを読み込みましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cc5bf7-7d05-4e71-90e9-816f9b5261d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset = datasets.load_digits()\n",
    "X = mnist_dataset.data\n",
    "y = mnist_dataset.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7b5499-4d99-4d1f-a9cf-61df5935556e",
   "metadata": {},
   "source": [
    "変数`X`は行列で，各行が手書き数字画像，各行がピクセルに対応しています．今回対象とする手書き数字画像は8x8ピクセルの画像ですので，人間には画像は行列で表現したほうが分かりやすいです．しかし，MNISTデータセットでは，データを扱いやすくするために8x8ピクセルの画像を1x64の横ベクトルで表現しています．変数`y`には，各行の手書き数字画像に対応する数字（ラベル）が格納されています．\n",
    "\n",
    "`X`には何件の手書き数字画像が格納されているのか確認してみましょう．下記コードを実行します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c34a40c-98a1-4728-aa44-708d487f1a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e77bfd-9120-4401-82f6-3948a0b20ec5",
   "metadata": {},
   "source": [
    "`X`の行列のサイズが表示されました．行が1797，列が64なので，手書き画像のデータ数は1797のようです．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829eeeea-2ce9-4317-8afc-91c6ecdf971c",
   "metadata": {},
   "source": [
    "行列`X`に格納されたデータを適当に眺めてみましょう．\n",
    "ここでは51番目に格納された手書き数字画像データを確認してみます．\n",
    "下記コードを実行してください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d677529-a3b4-417b-a59f-081fbc472756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 51番目のデータに対応するインデックス（行列は0行目から始まるので50ではなく51）\n",
    "k = 50\n",
    "\n",
    "# ターゲットとなる画像データとラベルを変数に格納\n",
    "target_data = X[k, :]\n",
    "target_label = y[k]\n",
    "\n",
    "print(\"{}番目の手書き数字 = \".format(k+1), target_label)\n",
    "\n",
    "# 51番目の画像データ（各ピクセルの値）\n",
    "target_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac4c3c0-a6f6-45c9-bdc1-4caa4e7112de",
   "metadata": {},
   "source": [
    "51番目の画像データの中身とそれに対応する数字が表示されました．\n",
    "画像データの横ベクトルが意味が分からないので，8x8の行列に直してみましょう．\n",
    "以下のコードを実行すると，行列の形を1x64から8x8に変更できます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb17c3f-ff68-4c75-8df4-ceabf45db63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_matrix = target_data.reshape(8, 8)\n",
    "target_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1f9430-0400-4aa6-a2f2-a0e2ad12a4c8",
   "metadata": {},
   "source": [
    "どのピクセルにどのような値がセットされているのか分かりやすくなりましたが，視覚的にどうなっているのか全然分かりません．\n",
    "下記コードを実行して行列データを可視化してみましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4382a8-225d-4c34-8fd0-d12bc68978ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(2, 1))\n",
    "plt.imshow(target_matrix, cmap=plt.cm.gray, interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973bc901-4904-4258-a6ae-62e1be8e9732",
   "metadata": {},
   "source": [
    "8x8ピクセルなので荒くて分かりづらいですが，遠目で見ると「2」という数字に見えますよね．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ef0ac5-f527-40de-9dbe-4b01fcce60d0",
   "metadata": {},
   "source": [
    "### 学習"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43100393-0525-4b77-a706-17c87e11a631",
   "metadata": {},
   "source": [
    "データの中身の理解が進んだので，K近傍法を用いて手書き数字画像の分類器を構築してみましょう．\n",
    "授業でも説明したように，教師あり学習を行いモデル構築とモデル評価を行うには訓練データとテストデータが必要になります．\n",
    "\n",
    "`sklearn`ライブラリには，データセットを訓練データとテストデータに分割する便利な関数`train_test_split`があります．\n",
    "下記コードを実行して，手元にあるデータセットを「訓練データ」と「テストデータ」に分割してみましょう．\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eeceeb-41c4-4576-b598-50b2b786a1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2, # データセットを訓練データ80%，テストデータ20%に分割\n",
    "    shuffle=True,  # 分割時にはデータセットをシャッフル\n",
    "    stratify=y)    # ラベルの分布が訓練データとテストデータで同じになるようにする"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2e0914-f294-4c6a-a76f-931fb928c708",
   "metadata": {},
   "source": [
    "`train_test_split`関数の第1引数，第2引数にセットされた`X`と`y`について，\n",
    "* 80%が訓練データ: `X_train`（画像データ）と`y_train`（対応するラベル）\n",
    "* 20%がテストデータ: `X_test`（画像データ）と`y_test`（対応するラベル）\n",
    "\n",
    "に分割されました．\n",
    "本当にデータセットは80:20に分割されているか確認してみましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387880dd-7581-4a85-817e-8c9f06ad00d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"訓練データのサイズ\", len(y_train))\n",
    "print(\"テストデータのサイズ\", len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb7d7eb-9bc5-4713-a53c-0301e2a7e862",
   "metadata": {},
   "source": [
    "大体80:20に分割されていますね．\n",
    "\n",
    "先の`train_test_split`関数の実行時には，stratify（層別化）オブションを有効にしていました．\n",
    "ラベルの分布が訓練データとテストデータで同じになっているか，確認しておきましょう．\n",
    "下記コードを実行します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7815c7-b1ee-420c-9f13-6b94571c6a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データの分布\n",
    "keys, counts = np.unique(y_train, return_counts=True)\n",
    "for key, count in zip(keys, counts):\n",
    "    print(key, \":\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076972bb-df3b-4d44-9b5e-4ae19b169f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータの分布\n",
    "keys, counts = np.unique(y_test, return_counts=True)\n",
    "for key, count in zip(keys, counts):\n",
    "    print(key, \":\", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacbcabb-07f0-42c9-b3b4-b15d1f6f009b",
   "metadata": {},
   "source": [
    "訓練データもテストデータも，0から9までの手書き数字データがほぼ均等に分布していることが確認できます．\n",
    "\n",
    "それでは，K近傍法で手書き数字画像の分類器を構築しましょう．\n",
    "MNISTデータセットはデータがキレイなため，特に前処理を行わなくても`sklearn`ライブラリを使えば分類器の構築は数行で終わってしまいます．\n",
    "\n",
    "今回はK近傍法のパラメータは\n",
    "* 近傍数`K`: 5\n",
    "* 距離関数`metric`: euclidean（ユークリッド距離）\n",
    "\n",
    "とし，以下のコードを実行して分類器を構築してみましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d835507-bd90-4490-bf38-31829a306d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "knn_model = KNeighborsClassifier(n_neighbors=K, metric=\"euclidean\")\n",
    "knn_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba869369-4008-4a3a-a946-80e3c595b98a",
   "metadata": {},
   "source": [
    "K近傍法による分類器が構築できました．\n",
    "\n",
    "それではテストデータから適当にピックアップし，分類器で正しく数値分類できるか確認してみましょう．\n",
    "下記コードを実行すると，テストデータからランダムに3個データを取得し分類器を適用します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ba9f3f-ff0f-4254-ae8b-8de4693c8953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "test_size = len(y_test)\n",
    "for _ in range(3):\n",
    "    idx = random.randint(0, test_size-1) # 何番目のテストデータか\n",
    "    target_data = X_test[idx, :].reshape(1, 64)\n",
    "    target_label = y_test[idx]\n",
    "\n",
    "    # K近傍法による推論\n",
    "    y_predicted = knn_model.predict(target_data)\n",
    "\n",
    "    # 手書き数字画像を表示\n",
    "    fig = plt.figure(figsize=(2, 1))\n",
    "    plt.imshow(target_data.reshape(8, 8), cmap=plt.cm.gray, interpolation='none')\n",
    "    plt.show()\n",
    "    \n",
    "    # 推論結果と正解ラベルの表示\n",
    "    print(\"予測ラベル: \", y_predicted)\n",
    "    print(\"正解ラベル: \", target_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a69c97-b315-44f9-a8cb-24a5e802f85e",
   "metadata": {},
   "source": [
    "分類結果はいかがでしたか．（位置が調整された）手書き数字画像であれば，K近傍法は驚くべきほど正確にラベルを予測することが確認できたのではないでしょうか．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9ebbb8-c2b8-43ca-92c7-98af78abb7e5",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "\n",
    "---\n",
    "## 例題2: 人工的に作られたある2次元データ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e194d5c3-b2d4-4868-93e4-c153d478b54f",
   "metadata": {},
   "source": [
    "次の例題では，機械学習の手順や評価指標の重要性を体験してみましょう．\n",
    "この例題で用いるのは，この例題のために作成した二次元データです．\n",
    "データの値に特に意味はありません．\n",
    "\n",
    "以下のコードを実行して，データを読み込んでください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baa1632-6053-4c6f-9f8c-e061fc8177b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/hontolab-courses/dmml-2023/main/dataset/imbalanced-data.tsv\"\n",
    "scatter_df = pd.read_table(url, header=0, sep='\\t')\n",
    "scatter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bc8831-d98f-42a1-86b7-1923b607f296",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='x1', y='x2', hue='label', data=scatter_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511a9a2a-d33a-4da9-a191-5ca7a14162f5",
   "metadata": {},
   "source": [
    "変数`scatter_df`には，ラベル0とラベル1のデータ点が合計108個格納されています．\n",
    "ラベルの分布を以下のコードを実行して確認してみましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39016963-ba57-484b-9070-f4d9f35e428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys, counts = np.unique(scatter_df.label, return_counts=True)\n",
    "for key, count in zip(keys, counts):\n",
    "    print(\"Label\", key, \"=\", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a044d063-8a05-426e-b289-3be44bfd3ca0",
   "metadata": {},
   "source": [
    "偏っていますね．ラベル1のデータがラベル0の3分の1程度しかありません．\n",
    "\n",
    "ではK近傍法を用いて，ラベルの分類器を構築してみましょう．\n",
    "この例題では`K=5`としてK近傍法を用います．\n",
    "今回はまず**誤った手続き**で分類器を構築・評価してみます．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80e433c-aafb-4f16-9978-54f265f56638",
   "metadata": {},
   "source": [
    "### 誤った手続き1: 交差検証を行わない"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e458434-6e32-491a-a1a3-f85589f1e31b",
   "metadata": {},
   "source": [
    "誤った手続きその1は「交差検証を行わない」です．\n",
    "用意したデータセットのサイズが十分に大きい場合，あるいはデータセットの準備の時点で訓練データとテストデータが分けて得られている場合は交差検証にこだわる必要はそれほどないかもしれません．\n",
    "そうでない場合は，交差検証をしなければ，分類器の汎化性能および性能評価そのものに問題が生じます．\n",
    "\n",
    "以下は交差検証を行わない，誤った教師あり学習の手続きです．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dafadd4-45b1-4b23-bbe5-9d4db85d6f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ準備\n",
    "X = scatter_df[scatter_df.columns[1:]]\n",
    "y = scatter_df[scatter_df.columns[0]]\n",
    "\n",
    "# データセットを70:30で訓練データ，評価データに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# K近傍法のモデルの定義\n",
    "K = 5\n",
    "knn_model = KNeighborsClassifier(n_neighbors=K, metric=\"euclidean\")\n",
    "\n",
    "# 学習\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# 推論\n",
    "y_predicted = knn_model.predict(X_test)\n",
    "\n",
    "# 評価\n",
    "accuracy = accuracy_score(y_test, y_predicted)\n",
    "print(\"kNN accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d61e1f2-634c-48e5-9f38-4d111fdbbe79",
   "metadata": {},
   "source": [
    "評価指標として精度（accuracy）を用いて，交差検証を行わずに分類器の構築と評価を行っています．\n",
    "みなさんの環境では適合率はいくつになったでしょうか．\n",
    "他の人と比べたり上記コードを再度実行してみてください．\n",
    "適合率が大きく異なることに気付くはずです．\n",
    "\n",
    "十分に大きくないデータセットに対して**交差検証を用いない場合，訓練データとテストデータの中身の分布に偏りが生じます**．\n",
    "その影響がモデルの構築および性能評価に出て，偶然結果が良くなったり悪くなったりします．\n",
    "分割した訓練データと評価データのラベルの分布を確認してみましょう．\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b9f4c7-0c90-4264-b7d9-50e73d455d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データの分布\n",
    "keys, counts = np.unique(y_train, return_counts=True)\n",
    "for key, count in zip(keys, counts):\n",
    "    print(\"Label\", key, \"=\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae46ac39-51c2-4923-a46f-0398053929ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータの分布\n",
    "keys, counts = np.unique(y_test, return_counts=True)\n",
    "for key, count in zip(keys, counts):\n",
    "    print(\"Label\", key, \"=\", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0535e49e-4db9-4675-9a1b-3a782d665de5",
   "metadata": {},
   "source": [
    "今回は`train_test_split`関数を用いるときにランダムにテストデータを分割しているため，人によっては訓練データとテストデータのラベルの分布が同じようになったケースもあるかもしれません．\n",
    "偶然を防ぎ汎化性能を向上させるためにも，交差検証を行う必要があります．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69a2337-1649-45f1-ba26-670790e45210",
   "metadata": {},
   "source": [
    "さて，上記の「誤った手続き」のコードは，交差検証のやり方以外にも問題があります．\n",
    "次の「誤った手続き」で見てみましょう．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffaa981-f364-4c8b-9e4b-e863036c0555",
   "metadata": {},
   "source": [
    "### 誤った手続き2: 層別化を行わない"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062ab0fc-a362-40ab-a08d-385815647211",
   "metadata": {},
   "source": [
    "誤った手続きその2は「層別化を行わない」です．\n",
    "今回用意したデータセットのようにラベルの分布に偏りがある場合は，その分布を考慮して訓練データとテストデータを分割しなければ，たまたま都合の良い（あるいは悪い）分類器を構築し，たまたま都合の良い（あるいは悪い）性能評価を行ってしまいます．\n",
    "そのため，**層別化**を行いながら訓練データとテストデータの分割を行う必要があります．\n",
    "\n",
    "以下は層別化を行わない交差検証を行った，誤った教師あり学習の手続きです．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26baa5c-a609-4801-bf9c-cd271c0cd98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの準備\n",
    "X = scatter_df[scatter_df.columns[1:]]\n",
    "y = scatter_df[scatter_df.columns[0]]\n",
    "\n",
    "# 層別化をしない5分割交差検証の準備（乱数を固定）\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=12345)\n",
    "\n",
    "# 評価指標（精度）\n",
    "score_funcs = ['accuracy']\n",
    "\n",
    "# K近傍法のモデルの定義\n",
    "K = 5\n",
    "knn_model = KNeighborsClassifier(n_neighbors=K, metric=\"euclidean\")\n",
    "\n",
    "# 交差検証をしながら分類器を構築・評価\n",
    "scores = cross_validate(knn_model, X, y, cv=k_fold, scoring=score_funcs)\n",
    "print(\"Accuracy list: \", scores['test_accuracy'])\n",
    "\n",
    "# 交差検証の評価スコアを平均としてまとめる\n",
    "print(\"kNN accuracy: \", np.mean(scores['test_accuracy']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812db171-5d80-4316-930b-396a219ff584",
   "metadata": {},
   "source": [
    "上記コードではデータ分割と交差検証，分類器構築，分類器評価を簡単にまとめて実行できる`cross_validate`関数を使っています．\n",
    "5分割交差検証の1回（ラウンド）ごとの精度スコアが`scores['test_accuracy']`に格納されています．また，その平均値の計算も行っています．\n",
    "一般に，交差検証を用いた性能評価ではこの平均値を用います．\n",
    "\n",
    "もうお気づきのとおり，適合率のスコアが交差検証のラウンドごとに大きく異なりますよね．\n",
    "層別化を行っていないからです．\n",
    "これは交差検証の平均スコアだけを見ていては気付きません．\n",
    "交差検証を行って学習と評価を複数回やったとしても，ラベル分布の偏りの影響を低減するにはもう一工夫必要となります．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406f8489-84f9-4fa1-b046-41a219334567",
   "metadata": {},
   "source": [
    "### 誤った手続き3: 評価指標が適切でない"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6c1014-fce6-4572-80ab-e7372c4639b3",
   "metadata": {},
   "source": [
    "誤った手続きその3は「評価指標が適切でない」です．\n",
    "以下は層別化交差検証を行ったが単純な精度を評価指標に使ってしまった，誤った教師あり学習の手続きです．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06288721-b436-4993-8f28-9b922c445304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの準備\n",
    "X = scatter_df[scatter_df.columns[1:]]\n",
    "y = scatter_df[scatter_df.columns[0]]\n",
    "\n",
    "# 「層別化」5分割交差検証の準備（乱数を固定）\n",
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=12345)\n",
    "\n",
    "# 評価指標（精度）\n",
    "score_funcs = ['accuracy']\n",
    "\n",
    "# K近傍法のモデルの定義\n",
    "K = 5\n",
    "knn_model = KNeighborsClassifier(n_neighbors=K, metric=\"euclidean\")\n",
    "\n",
    "# 交差検証をしながら分類器を構築・評価\n",
    "scores = cross_validate(knn_model, X, y, cv=k_fold, scoring=score_funcs)\n",
    "print(\"Accuracy list: \", scores['test_accuracy'])\n",
    "\n",
    "# 交差検証の評価スコアを平均としてまとめる\n",
    "print(\"kNN accuracy: \", np.mean(scores['test_accuracy']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f29c4e4-416d-40e7-a65b-4bc69ae20f27",
   "metadata": {},
   "source": [
    "「誤った手続き2」よりも精度のばらつきが小さくなりました．\n",
    "これで平均値を取れば一見正しい評価をしたような気がしますが，この例題の冒頭で解説したラベル分布の話を思い出してください．\n",
    "このデータセットはラベル0のほうがラベル1よりも3倍程度多く含んでいます．\n",
    "極端な話として，分類器の予測結果が常に「ラベル0」を返したとしても，単純な精度は不当に高い値をはじき出してしまいます．\n",
    "今回用意したデータセットのようにラベルの分布に偏りがある場合は，単純な精度ではなくラベル分布の偏りを考慮した**マクロ精度**や**AUC**，**MCC（マシューズ相関係数）**を用いる必要があります．\n",
    "\n",
    "最後に「より妥当な手続き」のコードを以下に記しておきます．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de8aaea-4290-4c65-ac37-e381f0a5671e",
   "metadata": {},
   "source": [
    "### より妥当な手続き"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d602b91-f0ec-4dd8-a9c2-3da2b8e099f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの準備\n",
    "X = scatter_df[scatter_df.columns[1:]]\n",
    "y = scatter_df[scatter_df.columns[0]]\n",
    "\n",
    "# 5分割「層別化」交差検証の準備（乱数を固定）\n",
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=12345)\n",
    "\n",
    "# 評価指標（マクロ精度（balanced accuracy），AUC）\n",
    "score_funcs = ['balanced_accuracy', 'roc_auc']\n",
    "\n",
    "# K近傍法のモデルの定義\n",
    "K = 5\n",
    "knn_model = KNeighborsClassifier(n_neighbors=K, metric=\"euclidean\")\n",
    "\n",
    "# 交差検証をしながら分類器を構築・評価\n",
    "scores = cross_validate(knn_model, X, y, cv=k_fold, scoring=score_funcs)\n",
    "print(\"Balanced accuracy list: \", scores['test_balanced_accuracy'])\n",
    "print(\"AUC list: \", scores['test_roc_auc'])\n",
    "\n",
    "# 交差検証の評価スコアを平均としてまとめる\n",
    "print()\n",
    "print(\"Balanced accuracy: \", np.mean(scores['test_balanced_accuracy']))\n",
    "print(\"AUC: \", np.mean(scores['test_roc_auc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8787643d-31ec-41c3-a971-d4d3b69d0d6f",
   "metadata": {},
   "source": [
    "上記はラベルの分布を考慮した，より妥当な分類器の構築と性能評価の手続きです．\n",
    "今回のデータの分類問題に対してK近傍法は優れていたのかを判断するには，他の分類器と比較をしなければ結論は出せません，分類器の構築および性能評価の流れはおおむね上記のような流れで行うと思っていただいてよいでしょう．\n",
    "\n",
    "今後より高性能の分類器を構築するには\n",
    "* データの変換（スケーリング，one-hotベクトル化）\n",
    "* 欠損値への対応\n",
    "* 特徴量選択\n",
    "* パラメータチューニング\n",
    "\n",
    "などが必要となります．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ee6f32-4437-4e09-b7fb-cf847f0a4628",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "\n",
    "---\n",
    "## 例題3: ある時期のアメリカ合衆国の年収調査データ\n",
    "最後の例題で扱うデータは，[1994年に作成されたアメリカ合衆国の国勢調査のデータセット（一部）](https://archive.ics.uci.edu/ml/datasets/Adult)です．\n",
    "機械学習の研究分野では著名なデータセットで通称\"Adult Dataset\"と呼ばれています．\n",
    "このデータセットには，\n",
    "* 年齢\n",
    "* 職業クラス\n",
    "* 最終学歴\n",
    "* 教育年数\n",
    "* 婚姻ステータス\n",
    "* 職業\n",
    "* 家族の構成\n",
    "* 人種\n",
    "* 性別\n",
    "* 資産売却益\n",
    "* 資産売却損\n",
    "* 週の労働時間\n",
    "* 母国\n",
    "* 年収（年5万ドル以上（>=50K） or それ以下（<50K））\n",
    "\n",
    "に関する情報が含まれています．\n",
    "このデータセットを使って，年収以外の情報から年収が年5万ドル以上か未満かを推定するさまざまな分類器を構築してみましょう．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7549e5f-c82a-4a50-9d62-424f67c0264d",
   "metadata": {},
   "source": [
    "以下のコードを実行すると，不必要なデータ列を削除し，ターゲットとなる年収情報を\n",
    "* 年5万ドル以上なら1\n",
    "* 年5万ドル未満なら0\n",
    "\n",
    "に置換したデータセットをデータフレーム変数`adult_df`に読み込みます．\n",
    "早速実行してみてください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f36366-8b77-4086-8422-9df6cb2ed134",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_dataset_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "\n",
    "features = [\n",
    "    \"age\",             # 年齢（数値）\n",
    "    \"workclass\",       # 職業クラス（カテゴリカル）\n",
    "    \"fnlwgt\",          # 不明\n",
    "    \"education\",       # 最終学歴（カテゴリカル）\n",
    "    \"education_num\",   # 教育年数（数値）\n",
    "    \"marital_status\",  # 婚姻ステータス（カテゴリカル）\n",
    "    \"occupation\",      # 職業（カテゴリカル）\n",
    "    \"relationship\",    # 家族の構成（カテゴリカル）\n",
    "    \"race\",            # 人種（カテゴリカル）\n",
    "    \"sex\",             # 性別（カテゴリカル）\n",
    "    \"capital_gain\",    # 資産売却益（数値）\n",
    "    \"capital_loss\",    # 資産売却損（数値）\n",
    "    \"hours_per_week\",  # 週の労働時間？（数値）\n",
    "    \"native_country\",  # 母国（カテゴリカル）\n",
    "    \"annual_income\"    # 年収（True of False）\n",
    "]\n",
    "\n",
    "adult_df = pd.read_table(\n",
    "    adult_dataset_url, sep=\", \", header=None,\n",
    "    names=features, engine='python', na_values=\"?\"\n",
    ").assign(\n",
    "    has_high_salary = lambda df: df[\"annual_income\"].map({\">50K\": True, \"<=50K\": False})\n",
    ").drop( # 不要 or 不明な特徴量を削除\n",
    "    columns=['fnlwgt', 'annual_income']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de8cef3-958f-49cb-89c9-00c6bc24ab23",
   "metadata": {},
   "source": [
    "読み込んだ`adult_df`を以下のコードで表示してみましょう．\n",
    "データは全部で32561レコードあることが分かります．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7926f80-e89c-4440-a32c-6b136f46abed",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8db716-b4b9-403c-90b6-f99c2f4cd714",
   "metadata": {},
   "source": [
    "今回の分類対象となる年収の分布を確認しておきましょう．\n",
    "下記コードを実行し，`adult_df`中の`has_high_salary`の値の分布を調べます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5726a36-e1f8-41da-be24-ddf6718ced26",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys, counts = np.unique(adult_df[\"has_high_salary\"], return_counts=True)\n",
    "for key, count in zip(keys, counts):\n",
    "    ratio = count / len(adult_df) * 100\n",
    "    print(key, \":\", count, \"({:.1f}%)\".format(ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e7e5cf-18ee-4940-a9b9-2e0d4ae5ba8e",
   "metadata": {},
   "source": [
    "年収が5万ドル以上のレコードと5万ドル未満のレコードの比は約1:3のようです．\n",
    "データに偏りがあるので，この点を意識して分類器の構築・評価を行う必要があります．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc7f482-ad5f-4247-95f9-ad3bad281c1c",
   "metadata": {},
   "source": [
    "では，先に進みましょう．\n",
    "分類器を構築するためにはデータセットを特徴データとラベルデータに分ける必要がありました．\n",
    "以下のコードを実行して特徴データを変数`X`に，ラベルデータを変数`y`に格納します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04555a1-ab6f-487c-93dd-083b0653ce1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最後の列の\"has_high_salary\"以外が特徴データ列\n",
    "X = adult_df[adult_df.columns[:-1]] \n",
    "\n",
    "# ターゲットラベルは\"has_high_salary\"\n",
    "y = adult_df[\"has_high_salary\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25002e47-92bb-47df-8a28-894f45d9084c",
   "metadata": {},
   "source": [
    "さて，`adult_df`を表示してお気づきのとおり，今回のデータセットには「年齢」「教育年数」「週の労働時間」のような**数値データ**もあれば，「職業クラス」「婚姻ステータス」「人種」のような**カテゴリカルデータ（質的データ）**も含まれています．\n",
    "カテゴリカルデータは数値ではないので，そのままでは数値処理を行うのが難しいです．\n",
    "そのため，機械学習を行うときにはカテゴリカルデータを**one-hotベクトル（one-hot表現，ダミー変数と呼ばれることもある）**に置き換えます．\n",
    "\n",
    "例えば，\n",
    "\n",
    "| ID | 年齢| 最終学歴 |\n",
    "| --- | --- | --- |\n",
    "| 1 | 38 | 大学 |\n",
    "| 2 | 58 | 高校 |\n",
    "| 3 | 27 | 大学院 |\n",
    "\n",
    "のようなデータセットがあった場合，最終学歴がカテゴリカルデータに相当します．\n",
    "このデータセットをOne-hotベクトル化すると，以下のようになります．\n",
    "\n",
    "| ID | 年齢| 最終学歴_大学 | 最終学歴_高校 |\n",
    "| --- | --- | --- | --- |\n",
    "| 1 | 38 | 1 | 0 |\n",
    "| 2 | 58 | 0 | 1 |\n",
    "| 3 | 27 | 0 | 0 | "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1767097f-d98c-44ed-8e79-004f5681fee8",
   "metadata": {},
   "source": [
    "今回のデータセットもone-hotベクトル化してみましょう．\n",
    "`pandas`ライブラリには，データフレームの中で指定した列をone-hotベクトルに変換してくれる便利な関数`get_dummies`があります．\n",
    "以下のコードを実行して，特徴データ`X`をone-hotベクトル化してみましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066329f1-3026-4cb2-b51d-81c4223a614a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ターゲットとなるカテゴリカルデータの特徴名（列名）\n",
    "categorical_features = [\n",
    "    \"workclass\",       # 職業クラス（カテゴリカル）\n",
    "    \"education\",       # 最終学歴（カテゴリカル）\n",
    "    \"marital_status\",  # 婚姻ステータス（カテゴリカル）\n",
    "    \"occupation\",      # 職業（カテゴリカル）\n",
    "    \"relationship\",    # 家族の構成（カテゴリカル）\n",
    "    \"race\",            # 人種（カテゴリカル）\n",
    "    \"sex\",             # 性別（カテゴリカル）\n",
    "    \"native_country\",  # 母国（カテゴリカル）    \n",
    "]\n",
    "\n",
    "# Xのカテゴリカルデータ列をone-hotベクトル化\n",
    "X_ = pd.get_dummies(X, columns=categorical_features, drop_first=True)\n",
    "\n",
    "# 最初の10件を表示\n",
    "X_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38318913-74f2-4d87-8f65-5b2f2ef0a13f",
   "metadata": {},
   "source": [
    "新たに得られたデータフレーム`X_`で`workclass`に関連する列に着目してみてください．\n",
    "元々は列`workclass`の値として\"Local-gov\"や\"Never_worked\"がありましたが，one-hotベクトル化されたデータフレーム`X_`では`workclass_Local-gov`などの列が新たに生成されています．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99e66dd-3edb-4945-bef9-c044e549c553",
   "metadata": {},
   "source": [
    "カテゴリカルデータに対する前処理が終わりましたが，まだ分類器を構築することはできません．\n",
    "データの正規化を行う必要があります．\n",
    "\n",
    "One-hotベクトルは1もしくは0の値を取ります．\n",
    "一方で，データフレーム`X_`には「年齢」「週の勤務時間」「資産売却益」など，連続値を取る特徴量があります．\n",
    "これらの特徴量はとり得る値の範囲やデータの分布，単位が特徴量ごとに大きく異なるため，特徴量（列）間の比較が難しくなり，機械学習の性能に悪影響が出る可能性があります．\n",
    "このような問題に対処するために，データの**スケーリング**を行いましょう．\n",
    "\n",
    "一般に，スケーリングの方法には\n",
    "* 正規化: 最小値-最大値でスケーリングする方法\n",
    "* 標準化: データの分布が平均0，標準偏差1になるようスケーリングする方法\n",
    "\n",
    "の2種類がよく用いられます．\n",
    "ここでは簡単のため，連続値データ列もone-hotベクトルデータ列もすべて標準化することにしましょう．\n",
    "以下のコードでデータを標準化します．\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d836549-aeb0-4a8b-9452-29b1742e00fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準化のための変換器を用意\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# 標準化\n",
    "X_ = pd.DataFrame(scaler.fit_transform(X_), columns=X_.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e30b324-daf0-4793-878a-ca74ba9dc96f",
   "metadata": {},
   "source": [
    "データフレーム`X_`のデータが標準化されました．\n",
    "\n",
    "前処理が終わったので，いよいよ分類器を構築しましょう．\n",
    "今回は\n",
    "* ロジスティック回帰\n",
    "* 決定木\n",
    "* K近傍法（K=5）\n",
    "\n",
    "の3種類の分類器を構築します．\n",
    "簡単のため，ロジスティック回帰および決定木はデフォルトパラメータで分類器を構築します．\n",
    "また，分類器の性能評価は5分割の層別化交差検証，評価指標は「マクロ精度（balanced accuracy）」「適合率（precision）」の2つを用いることにします．\n",
    "\n",
    "やや長いですが，下記コードを実行し，交差検証を用いて分類器の構築，性能評価をしてみましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc283c8-e0e1-4c6f-b321-c42d6032f1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 時間計測に使う\n",
    "import time\n",
    "\n",
    "# 評価スコアを入れる場所\n",
    "accuracy_scores = {'logistic_regression': [],\n",
    "                   'decision_tree': [],\n",
    "                   'kNN': []}\n",
    "precision_scores = {'logistic_regression': [],\n",
    "                    'decision_tree': [],\n",
    "                    'kNN': []}\n",
    "\n",
    "training_runtimes = {'logistic_regression': [],\n",
    "                     'decision_tree': [],\n",
    "                     'kNN': []}\n",
    "\n",
    "prediction_runtimes = {'logistic_regression': [],\n",
    "                       'decision_tree': [],\n",
    "                       'kNN': []}\n",
    "\n",
    "# 5分割層別化交差検証\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "for train_idx, test_idx in kfold.split(X_, y):\n",
    "    # train_idx, test_idxには，データフレーム中の何番目のデータを用いるかの\n",
    "    # リストが入っている．\n",
    "    # 3つの分類器に対して同じデータを用いて評価すること．\n",
    "    X_train = X_.iloc[train_idx]\n",
    "    X_test = X_.iloc[test_idx]\n",
    "    y_train = y.iloc[train_idx]\n",
    "    y_test = y.iloc[test_idx]\n",
    "    \n",
    "    for clf_name in ['logistic_regression', 'decision_tree', 'kNN']:\n",
    "        if clf_name == 'logistic_regression':\n",
    "            # ロジスティック回帰\n",
    "            model = LogisticRegression()\n",
    "        elif clf_name == 'decision_tree':\n",
    "            # 決定木\n",
    "            model = DecisionTreeClassifier(criterion='entropy')\n",
    "        else:\n",
    "            # K近傍法\n",
    "            model = KNeighborsClassifier(n_neighbors=5, metric=\"euclidean\")\n",
    "        \n",
    "        # 学習（実行時間を計測しておく）\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        training_runtimes[clf_name].append(time.time() - start_time)\n",
    "        \n",
    "        # 推論（実行時間を計測しておく）\n",
    "        start_time = time.time()\n",
    "        y_predicted = model.predict(X_test)\n",
    "        prediction_runtimes[clf_name].append(time.time() - start_time)\n",
    "        \n",
    "        # 評価スコアの計算\n",
    "        precision = precision_score(y_test, y_predicted)\n",
    "        precision_scores[clf_name].append(precision)          \n",
    "        accuracy = balanced_accuracy_score(y_test, y_predicted)\n",
    "        accuracy_scores[clf_name].append(accuracy)\n",
    "    \n",
    "    \n",
    "# 交差検証の結果を平均して，最終の性能評価を算出\n",
    "print(\"\\n==== Precision =====\")\n",
    "for method in precision_scores:\n",
    "    print(method, \":\", np.mean(precision_scores[method]))\n",
    "    \n",
    "print(\"\\n==== Balanced accuracy =====\")\n",
    "for method in accuracy_scores:\n",
    "    print(method, \":\", np.mean(accuracy_scores[method]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eece034-aa6e-4f8f-bb83-75f55639c98c",
   "metadata": {},
   "source": [
    "評価に用いたデータには年収の分布に偏りがあったため，適合率よりもマクロ精度をより重視した方がよいでしょうが，今回のHands-onコードでは，適合率とマクロ精度の2つの評価指標ともに，ロジスティック回帰の評価値が最も高くなりました．\n",
    "単純な手法であるK近傍法も，そこまで悪くない性能を示しています．\n",
    "ハイパーパラメータの調整はしなかったので，どの分類器ももう少し性能改善の余地はあるでしょう．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3855e505-4789-4d2f-b055-b65fe645fef4",
   "metadata": {},
   "source": [
    "最後に学習，推論にかかった時間の平均値も表示してみましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5276bb0-132d-4c5c-8b05-8c4a1c4de0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n==== Training runtime (s)=====\")\n",
    "for method in training_runtimes:\n",
    "    print(method, \":\", np.mean(training_runtimes[method]))\n",
    "    \n",
    "print(\"\\n==== Prediction runtime (s)=====\")\n",
    "for method in prediction_runtimes:\n",
    "    print(method, \":\", np.mean(prediction_runtimes[method]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be4ab58-80d7-4c2f-aaad-63c05358cb7a",
   "metadata": {},
   "source": [
    "* ロジスティック回帰および決定木は，学習に時間がかかり推論は瞬時に終わる\n",
    "* K近傍法は，学習は一瞬で終わり推論に非常に時間がかかっている\n",
    "\n",
    "ことが確認できます．\n",
    "最終的にはなにかしらの推論を行うために機械学習を用いるわけですから，推論に時間がかかると問題になるケースではK近傍法は割けた方がよいでしょう．\n",
    "一方，推論の実行時間が気にならないのであれば，単純でもそこそこ性能を発揮するK近傍法は候補のひとつに入る可能性があるでしょう．"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
